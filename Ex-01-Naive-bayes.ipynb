{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data\n",
    "The SMS Spam Collection v.1 is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged according being ham (legitimate) or spam. The distribution is a total of 4,827 SMS legitimate messages (86.6%) and a total of 747 (13.4%) spam messages.\n",
    "\n",
    "If we open the dataset, we will see that it has the format [label] [tab] [message]\n",
    "\n",
    "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
    "\n",
    "ham\t    U dun say so early hor... U c already then say...\n",
    "\n",
    "\n",
    "\n",
    "You can collect the data from here: https://archive.ics.uci.edu/ml/datasets/sms+spam+collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ex-01-Naive-bayes.ipynb  SMSSpamCollection\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renuk/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# read data into dataframe \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_table('SMSSpamCollection',\n",
    "                   sep='\\t', \n",
    "                   header=None,\n",
    "                   names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of       label                                            message\n",
       "0         0  go until jurong point crazi avail onli in bugi...\n",
       "1         0                              ok lar joke wif u oni\n",
       "2         1  free entri in 2 a wkli comp to win fa cup fina...\n",
       "3         0        u dun say so earli hor u c alreadi then say\n",
       "4         0  nah i dont think he goe to usf he live around ...\n",
       "5         1  freemsg hey there darl it been 3 week now and ...\n",
       "6         0  even my brother is not like to speak with me t...\n",
       "7         0  as per your request mell mell oru minnaminungi...\n",
       "8         1  winner as a valu network custom you have been ...\n",
       "9         1  had your mobil 11 month or more u r entitl to ...\n",
       "10        0  im gon na be home soon and i dont want to talk...\n",
       "11        1  six chanc to win cash from 100 to 20000 pound ...\n",
       "12        1  urgent you have won a 1 week free membership i...\n",
       "13        0  ive been search for the right word to thank yo...\n",
       "14        0                  i have a date on sunday with will\n",
       "15        1  xxxmobilemovieclub to use your credit click th...\n",
       "16        0                                  oh kim watch here\n",
       "17        0  eh u rememb how 2 spell hi name ye i did he v ...\n",
       "18        0  fine if that the way u feel that the way it go...\n",
       "19        1  england v macedonia dont miss the goalsteam ne...\n",
       "20        0              is that serious how you spell hi name\n",
       "21        0           im go to tri for 2 month ha ha onli joke\n",
       "22        0     so ü pay first lar then when is da stock comin\n",
       "23        0  aft i finish my lunch then i go str down lor a...\n",
       "24        0  ffffffffff alright no way i can meet up with y...\n",
       "25        0  just forc myself to eat a slice im realli not ...\n",
       "26        0                          lol your alway so convinc\n",
       "27        0  did you catch the bu are you fri an egg did yo...\n",
       "28        0  im back amp were pack the car now ill let you ...\n",
       "29        0  ahhh work i vagu rememb that what doe it feel ...\n",
       "...     ...                                                ...\n",
       "5542      0            armand say get your ass over to epsilon\n",
       "5543      0              u still havent got urself a jacket ah\n",
       "5544      0  im take derek amp taylor to walmart if im not ...\n",
       "5545      0        hi it in durban are you still on thi number\n",
       "5546      0            ic there are a lotta childporn car then\n",
       "5547      1  had your contract mobil 11 mnth latest motorol...\n",
       "5548      0                       no i wa tri it all weekend v\n",
       "5549      0  you know wot peopl wear t shirt jumper hat bel...\n",
       "5550      0          cool what time you think you can get here\n",
       "5551      0     wen did you get so spiritu and deep that great\n",
       "5552      0  have a safe trip to nigeria wish you happi and...\n",
       "5553      0                           hahahaus your brain dear\n",
       "5554      0  well keep in mind ive onli got enough ga for o...\n",
       "5555      0  yeh indian wa nice tho it did kane me off a bi...\n",
       "5556      0  ye i have so that whi u text pshewmiss you so ...\n",
       "5557      0  no i meant the calcul is the same that ltgt un...\n",
       "5558      0                               sorri ill call later\n",
       "5559      0  if you arent here in the next ltgt hour imma f...\n",
       "5560      0                       anyth lor juz both of us lor\n",
       "5561      0  get me out of thi dump heap my mom decid to co...\n",
       "5562      0  ok lor soni ericsson salesman i ask shuhui the...\n",
       "5563      0                                 ard 6 like dat lor\n",
       "5564      0  whi dont you wait til at least wednesday to se...\n",
       "5565      0                                          huh y lei\n",
       "5566      1  remind from o2 to get 250 pound free call cred...\n",
       "5567      1  thi is the 2nd time we have tri 2 contact u u ...\n",
       "5568      0                    will ü b go to esplanad fr home\n",
       "5569      0       piti wa in mood for that soani other suggest\n",
       "5570      0  the guy did some bitch but i act like id be in...\n",
       "5571      0                            rofl it true to it name\n",
       "\n",
       "[5572 rows x 2 columns]>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "Once we have our data ready, it is time to do some preprocessing. We will focus on removing useless variance for our task at hand. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we have to convert the labels from strings to binary values for our classifier:\n",
    "df['label'] = df.label.map({'ham': 0, 'spam': 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second, convert all characters in the message to lower case:\n",
    "\n",
    "df['message'] = df.message.map(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third, remove any punctuation:\n",
    "\n",
    "df['message'] = df.message.str.replace('[^\\w\\s]', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fourth, tokenize the messages into into single words using nltk. \n",
    "#First, we have to import and download the tokenizer from the console:\n",
    "\n",
    "\n",
    "#An installation window will appear. Go to the \"Models\" tab and select \"punkt\" from the \"Identifier\" column. \n",
    "#Then click \"Download\" and it will install the necessary files.\n",
    "#Then it should work! Now we can apply the tokenization:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df['message'].apply(nltk.word_tokenize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fifth, we will perform some word stemming.\n",
    "\n",
    "The idea of stemming is to normalize our text for all variations of words carry the same meaning,\n",
    "\n",
    "regardless of the tense. One of the most popular stemming algorithms is the Porter Stemmer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    " \n",
    "df['message'] = df['message'].apply(lambda x: [stemmer.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will transform the data into occurrences,\n",
    "which will be the features that we will feed into our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# This converts the list of words into space-separated strings\n",
    "df['message'] = df['message'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "counts = count_vect.fit_transform(df['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could leave it as the simple word-count per message, \n",
    "but it is better to use Term Frequency Inverse Document Frequency, more known as tf-idf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 8169)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer().fit(counts)\n",
    "\n",
    "counts = transformer.transform(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "Now that we have performed feature extraction from our data, it is time to build our model. We will start by splitting our data into training and test sets:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, all that we have to do is initialize the Naive Bayes Classifier and fit the data. \n",
    "For text classification problems, the Multinomial Naive Bayes Classifier is well-suited:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB().fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model\n",
    "Once we have put together our classifier, we can evaluate its performance in the testing set:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9479820627802691\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "print(np.mean(predicted == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[964   0]\n",
      " [ 58  93]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
