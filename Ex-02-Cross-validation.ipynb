{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This tutorial is divided into 3 parts:\n",
    "\n",
    "Train and Test Split python code.\n",
    "\n",
    "k-fold Cross Validation Split python code.\n",
    "\n",
    "Using API implement k-fold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Train and Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and test split involves separating a dataset into two parts:\n",
    "    \n",
    "\n",
    "Training Dataset.\n",
    "\n",
    "Test Dataset.\n",
    "\n",
    "The training dataset is used by the machine learning algorithm to train the model.\n",
    "The test dataset is held back and is used to evaluate the performance of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can implement the train and test split of a dataset in a single function.\n",
    "\n",
    "Below is a function named train_test_split() to split a dataset into a train and test split. It accepts two arguments, the dataset to split as a list of lists and an optional split percentage.\n",
    "\n",
    "A default split percentage of 0.6 or 60% is used. This will assign 60% of the dataset to the training dataset and leave the remaining 40% to the test dataset. A 60/40 for train/test is a good default split of the data.\n",
    "\n",
    "The function first calculates how many rows the training set requires from the provided dataset. A copy of the original dataset is made. Random rows are selected and removed from the copied dataset and added to the train dataset until the train dataset contains the target number of rows.\n",
    "\n",
    "The rows that remain in the copy of the dataset are then returned as the test dataset.\n",
    "\n",
    "The randrange() function from the random model is used to generate a random integer in the range between 0 and the size of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [3], [4], [6], [5], [8]]\n",
      "[[2], [7], [9], [10]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from random import seed\n",
    "from random import randrange\n",
    " \n",
    "# Split a dataset into a train and test set\n",
    "def train_test_split(dataset, split=0.60):\n",
    "\ttrain = list()\n",
    "\ttrain_size = split * len(dataset)\n",
    "\tdataset_copy = list(dataset)\n",
    "\twhile len(train) < train_size:\n",
    "\t\tindex = randrange(len(dataset_copy))\n",
    "\t\ttrain.append(dataset_copy.pop(index))\n",
    "\treturn train, dataset_copy\n",
    " \n",
    "# test train/test split\n",
    "seed(2) # You can change the value to see \n",
    "\n",
    "dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n",
    "train, test = train_test_split(dataset)\n",
    "print(train)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8], [5], [7], [2], [6], [1]]\n",
      "[[3], [4], [9], [10]]\n"
     ]
    }
   ],
   "source": [
    "seed(12) # You can change the value to see \n",
    "\n",
    "dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n",
    "train, test = train_test_split(dataset)\n",
    "print(train)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. k-fold Cross Validation Split\n",
    "\n",
    "A limitation of using the train and test split method is that you get a noisy estimate of algorithm performance.\n",
    "\n",
    "The k-fold cross validation method (also called just cross validation) is a resampling method that provides a more accurate estimate of algorithm performance.\n",
    "\n",
    "It does this by first splitting the data into k groups. The algorithm is then trained and evaluated k times and the performance summarized by taking the mean performance score. Each group of data is called a fold, hence the name k-fold cross-validation.\n",
    "\n",
    "It works by first training the algorithm on the k-1 groups of the data and evaluating it on the kth hold-out group as the test set. This is repeated so that each of the k groups is given an opportunity to be held out and used as the test set.\n",
    "\n",
    "As such, the value of k should be divisible by the number of rows in your training dataset, to ensure each of the k groups has the same number of rows.\n",
    "\n",
    "You should choose a value for k that splits the data into groups with enough rows that each group is still representative of the original dataset. A good default to use is k=3 for a small dataset or k=10 for a larger dataset. A quick way to check if the fold sizes are representative is to calculate summary statistics such as mean and standard deviation and see how much the values differ from the same statistics on the whole dataset.\n",
    "\n",
    "We can reuse what we learned in the previous section in creating a train and test split here in implementing k-fold cross validation.\n",
    "\n",
    "Instead of two groups, we must return k-folds or k groups of data.\n",
    "\n",
    "Below is a function named cross_validation_split() that implements the cross validation split of data.\n",
    "\n",
    "As before, we create a copy of the dataset from which to draw randomly chosen rows.\n",
    "\n",
    "We calculate the size of each fold as the size of the dataset divided by the number of folds required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fold size = total rows / total folds\n",
    "\n",
    "If the dataset does not cleanly divide by the number of folds, \n",
    "there may be some remainder rows and they will not be used in the split.\n",
    "\n",
    "We then create a list of rows with the required size and \n",
    "add them to a list of folds which is then returned at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test this resampling method on the same small contrived dataset as above. Each row has only a single column value, but we can imagine how this might scale to a standard machine learning dataset.\n",
    "\n",
    "The complete example is listed below.\n",
    "\n",
    "As before, we fix the seed for the random number generator to ensure that each time the code is executed that the same rows are used in the same folds.\n",
    "\n",
    "A k value of 4 is used for demonstration purposes. We would expect that the 10 rows divided into 4 folds will result in 2 rows per fold, with a remainder of 2 that will not be used in the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[3], [2]], [[7], [1]], [[8], [9]], [[10], [6]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from random import seed\n",
    "from random import randrange\n",
    " \n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, folds):\n",
    "\tdataset_split = list()\n",
    "\tdataset_copy = list(dataset)\n",
    "\tfold_size = int(len(dataset) / folds)\n",
    "\tfor i in range(folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split\n",
    " \n",
    "# test cross validation split\n",
    "seed(1)\n",
    "dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n",
    "folds = cross_validation_split(dataset, 4)\n",
    "print(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[6], [9], [8], [2], [4]], [[1], [10], [3], [7], [5]]]\n"
     ]
    }
   ],
   "source": [
    "seed(76)\n",
    "dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n",
    "folds = cross_validation_split(dataset, 2)\n",
    "print(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cross-Validation API\n",
    "\n",
    "We do not have to implement k-fold cross-validation manually.\n",
    "\n",
    "The scikit-learn library provides an implementation that will split a given data sample up.\n",
    "\n",
    "The KFold() scikit-learn class can be used.\n",
    "\n",
    "It takes as arguments the number of splits, whether or not to shuffle the sample,\n",
    "\n",
    "and the seed for the pseudorandom number generator used prior to the shuffle.\n",
    "\n",
    "For example, we can create an instance that splits a dataset into 3 folds, \n",
    "\n",
    "shuffles prior to the split, and uses a value of 1 for the pseudorandom number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can create an instance that splits a dataset into 3 folds, \n",
    "shuffles prior to the split, and uses a value of 1 for the pseudorandom number generator.\n",
    "\n",
    "kfold = KFold(3, True, 1)\n",
    "\n",
    "The split() function can then be called on the class where the data sample is provided as an argument. Called repeatedly, the split will return each group of train and test sets. Specifically, arrays are returned containing the indexes into the original data sample of observations to use for train and test sets on each iteration.\n",
    "\n",
    "For example, we can enumerate the splits of the indices for a data sample using the created KFold instance as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# scikit-learn k-fold cross-validation\n",
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "# data sample\n",
    "data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.3 0.4 0.5 0.6], test: [0.1 0.2]\n",
      "train: [0.1 0.2 0.4 0.6], test: [0.3 0.5]\n",
      "train: [0.1 0.2 0.3 0.5], test: [0.4 0.6]\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(3, True, 87)\n",
    "# enumerate splits\n",
    "for train, test in kfold.split(data):\n",
    "\tprint('train: %s, test: %s' % (data[train], data[test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.2 0.3 0.4 0.6], test: [0.1 0.5]\n",
      "train: [0.1 0.3 0.5 0.6], test: [0.2 0.4]\n",
      "train: [0.1 0.2 0.4 0.5], test: [0.3 0.6]\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(3, True, 54)    # changing the seed value generate new sets\n",
    "# enumerate splits\n",
    "for train, test in kfold.split(data):\n",
    "\tprint('train: %s, test: %s' % (data[train], data[test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
