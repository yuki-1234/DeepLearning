{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Word Embeddings using Keras  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define our dataset.\n",
    "\n",
    "We will be using a very simple custom dataset that will contain reviews above movies.\n",
    "\n",
    "The following script creates our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    # Positive Reviews\n",
    "\n",
    "    'This is an excellent movie',\n",
    "    'The move was fantastic I like it',\n",
    "    'You should watch it is brilliant',\n",
    "    'Exceptionally good',\n",
    "    'Wonderfully directed and executed I like it',\n",
    "    'Its a fantastic series',\n",
    "    'Never watched such a brillent movie',\n",
    "    'It is a Wonderful movie',\n",
    "\n",
    "    # Negtive Reviews\n",
    "\n",
    "    \"horrible acting\",\n",
    "    'waste of money',\n",
    "    'pathetic picture',\n",
    "    'It was very boring',\n",
    "    'I did not like the movie',\n",
    "    'The movie was horrible',\n",
    "    'I will not recommend',\n",
    "    'The acting is pathetic'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our corpus has 8 positive reviews and 8 negative reviews. \n",
    "\n",
    "The next step is to create label set for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = array([1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter to the Embedding() layer is the vocabulary, or number of unique words in the corpus. \n",
    "\n",
    "Let's first find the total number of words in our corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "all_words = []\n",
    "for sent in corpus:\n",
    "    tokenize_word = word_tokenize(sent)\n",
    "    for word in tokenize_word:\n",
    "        all_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve all the unique words from a list by passing the list into the set function, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "unique_words = set(all_words)\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output you will see \"45\", which is the number of unique words in our corpus.\n",
    "\n",
    "The Embedding layer expects the words to be in numeric form. Therefore, we need to convert the sentences in our corpus to numbers.\n",
    "\n",
    "One way to convert text to numbers is by using the one_hot function from the keras.preprocessing.text library. \n",
    "\n",
    "The function takes sentence and the total length of the vocabulary and returns the sentence in numeric form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 26, 4, 13, 31], [7, 26, 12, 36, 40, 11, 36], [2, 43, 3, 36, 26, 8], [9, 37], [35, 29, 34, 16, 40, 11, 36], [23, 25, 36, 10], [4, 36, 12, 25, 10, 31], [36, 26, 25, 8, 31], [22, 9], [36, 21, 14], [42, 9], [36, 12, 8, 39], [40, 11, 13, 11, 7, 31], [7, 31, 12, 22], [40, 3, 13, 25], [7, 9, 26, 42]]\n"
     ]
    }
   ],
   "source": [
    "vocab_length = 45\n",
    "embedded_sentences = [one_hot(sent, vocab_length) for sent in corpus]\n",
    "print(embedded_sentences )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding layer expects sentences to be of equal size. \n",
    "\n",
    "However, our encoded sentences are of different sizes.\n",
    "\n",
    "One way to make all the sentences of uniform size is to increase the lenght of all the sentences and make it equal to the length of the largest sentence. \n",
    "\n",
    "Let's first find the largest sentence in our corpus and then we will increase the length of all the sentences to the length of the largest sentence. To do so, execute the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = lambda sentence: len(word_tokenize(sentence))\n",
    "longest_sentence = max(corpus, key=word_count)\n",
    "length_long_sentence = len(word_tokenize(longest_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_long_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next to make all the sentences of equal size, we will add zeros to the empty indexes that will be created as a result of increasing the sentence length\n",
    "\n",
    "To append the zeros at the end of the sentencses, we can use the pad_sequences method.\n",
    "\n",
    "The first parameter is the list of encoded sentences of unequal sizes, the second parameter is the size of the longest sentence or the padding index, while the last parameter is padding where you specify post to add padding at the end of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2 26  4 13 31  0  0]\n",
      " [ 7 26 12 36 40 11 36]\n",
      " [ 2 43  3 36 26  8  0]\n",
      " [ 9 37  0  0  0  0  0]\n",
      " [35 29 34 16 40 11 36]\n",
      " [23 25 36 10  0  0  0]\n",
      " [ 4 36 12 25 10 31  0]\n",
      " [36 26 25  8 31  0  0]\n",
      " [22  9  0  0  0  0  0]\n",
      " [36 21 14  0  0  0  0]\n",
      " [42  9  0  0  0  0  0]\n",
      " [36 12  8 39  0  0  0]\n",
      " [40 11 13 11  7 31  0]\n",
      " [ 7 31 12 22  0  0  0]\n",
      " [40  3 13 25  0  0  0]\n",
      " [ 7  9 26 42  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "padded_sentences = pad_sequences(embedded_sentences, length_long_sentence, padding='post')\n",
    "print(padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything that we need to create a sentiment classification model using word embeddings.\n",
    "\n",
    "We will create a very simple text classification model with an embedding layer and no hidden layers. \n",
    "\n",
    "Look at the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_length, 20, input_length=length_long_sentence))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the script above, we create a Sequential model and add the Embedding layer as the first layer to the model.\n",
    "\n",
    "The length of the vocabulary is specified by the vocab_length parameter. \n",
    "\n",
    "The dimension of each word vector will be 20 and the input_length will be the length of the longest sentence, which is 7. \n",
    "\n",
    "Next, the Embedding layer is flattened so that it can be directly used with the densely connected layer. \n",
    "\n",
    "Since it is a binary classification problem, we use the sigmoid function as the loss function at the dense layer.\n",
    "\n",
    "Next, we will compile the model and print the summary of our model, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 7, 20)             900       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 141       \n",
      "=================================================================\n",
      "Total params: 1,041\n",
      "Trainable params: 1,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the first layer has 900 trainable parameters. \n",
    "\n",
    "This is because our vocabulary size is 45 and each word will be presented as a 20 dimensional vector.\n",
    "\n",
    "Hence the total number of trainable parameters will be 900. \n",
    "\n",
    "Similarly, the output from the embedding layer will be a sentence with 7 words where each word is represented by a 20 dimensional vector. \n",
    "\n",
    "However, when the 2D output is flattened, we get a 140 dimensional vector (7 x 20). The flattened vector is directly connected to the dense layer that contains 1 neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the model on our data using the fit method, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renuk/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6971 - acc: 0.4375\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 74us/step - loss: 0.6933 - acc: 0.5000\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 145us/step - loss: 0.6902 - acc: 0.5000\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 88us/step - loss: 0.6868 - acc: 0.5625\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 92us/step - loss: 0.6834 - acc: 0.6875\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 95us/step - loss: 0.6799 - acc: 0.6875\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 118us/step - loss: 0.6763 - acc: 0.8125\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 138us/step - loss: 0.6728 - acc: 0.8125\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 131us/step - loss: 0.6692 - acc: 0.8125\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 306us/step - loss: 0.6656 - acc: 0.8125\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 167us/step - loss: 0.6620 - acc: 0.8125\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 133us/step - loss: 0.6584 - acc: 0.8750\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 104us/step - loss: 0.6548 - acc: 0.8750\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 132us/step - loss: 0.6512 - acc: 0.8750\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 148us/step - loss: 0.6476 - acc: 0.8750\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 193us/step - loss: 0.6440 - acc: 0.8750\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 129us/step - loss: 0.6403 - acc: 0.8750\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 410us/step - loss: 0.6367 - acc: 0.8750\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 188us/step - loss: 0.6331 - acc: 0.8750\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 110us/step - loss: 0.6294 - acc: 0.8750\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 99us/step - loss: 0.6257 - acc: 0.8750\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 123us/step - loss: 0.6219 - acc: 0.8750\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 477us/step - loss: 0.6182 - acc: 0.8750\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 158us/step - loss: 0.6144 - acc: 0.8750\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 180us/step - loss: 0.6106 - acc: 0.8750\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 246us/step - loss: 0.6068 - acc: 0.8750\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 254us/step - loss: 0.6029 - acc: 0.8750\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 114us/step - loss: 0.5990 - acc: 0.8750\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 108us/step - loss: 0.5950 - acc: 0.8750\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 129us/step - loss: 0.5910 - acc: 0.8750\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 197us/step - loss: 0.5870 - acc: 0.8750\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 211us/step - loss: 0.5830 - acc: 0.8750\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 199us/step - loss: 0.5789 - acc: 0.8750\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 113us/step - loss: 0.5748 - acc: 0.8750\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 474us/step - loss: 0.5707 - acc: 0.9375\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 232us/step - loss: 0.5665 - acc: 0.9375\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 110us/step - loss: 0.5623 - acc: 0.9375\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 106us/step - loss: 0.5581 - acc: 0.9375\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 109us/step - loss: 0.5538 - acc: 0.9375\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 415us/step - loss: 0.5495 - acc: 0.9375\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.5453 - acc: 0.9375\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 203us/step - loss: 0.5409 - acc: 0.9375\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 119us/step - loss: 0.5366 - acc: 0.9375\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 521us/step - loss: 0.5322 - acc: 0.9375\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 456us/step - loss: 0.5278 - acc: 0.9375\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 123us/step - loss: 0.5233 - acc: 0.9375\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 130us/step - loss: 0.5189 - acc: 0.9375\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 386us/step - loss: 0.5144 - acc: 0.9375\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 234us/step - loss: 0.5100 - acc: 0.9375\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 293us/step - loss: 0.5055 - acc: 0.9375\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 350us/step - loss: 0.5010 - acc: 0.9375\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 196us/step - loss: 0.4965 - acc: 0.9375\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 213us/step - loss: 0.4920 - acc: 0.9375\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 161us/step - loss: 0.4875 - acc: 0.9375\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 167us/step - loss: 0.4830 - acc: 0.9375\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 255us/step - loss: 0.4784 - acc: 0.9375\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 329us/step - loss: 0.4739 - acc: 0.9375\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 160us/step - loss: 0.4694 - acc: 0.9375\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 115us/step - loss: 0.4648 - acc: 0.9375\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 150us/step - loss: 0.4603 - acc: 0.9375\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 195us/step - loss: 0.4557 - acc: 0.9375\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 160us/step - loss: 0.4512 - acc: 0.9375\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 174us/step - loss: 0.4467 - acc: 0.9375\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 112us/step - loss: 0.4421 - acc: 0.9375\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 102us/step - loss: 0.4376 - acc: 0.9375\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 451us/step - loss: 0.4330 - acc: 0.9375\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 198us/step - loss: 0.4285 - acc: 0.9375\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 170us/step - loss: 0.4240 - acc: 0.9375\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 96us/step - loss: 0.4195 - acc: 0.9375\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 177us/step - loss: 0.4150 - acc: 0.9375\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 335us/step - loss: 0.4105 - acc: 0.9375\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 180us/step - loss: 0.4060 - acc: 0.9375\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 145us/step - loss: 0.4016 - acc: 0.9375\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 220us/step - loss: 0.3971 - acc: 0.9375\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 303us/step - loss: 0.3927 - acc: 0.9375\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 105us/step - loss: 0.3883 - acc: 0.9375\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 264us/step - loss: 0.3839 - acc: 0.9375\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 188us/step - loss: 0.3795 - acc: 0.9375\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 254us/step - loss: 0.3752 - acc: 0.9375\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 180us/step - loss: 0.3709 - acc: 0.9375\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 134us/step - loss: 0.3666 - acc: 0.9375\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 250us/step - loss: 0.3623 - acc: 0.9375\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 270us/step - loss: 0.3580 - acc: 0.9375\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 308us/step - loss: 0.3538 - acc: 0.9375\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 535us/step - loss: 0.3496 - acc: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 136us/step - loss: 0.3455 - acc: 0.9375\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 148us/step - loss: 0.3413 - acc: 0.9375\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 109us/step - loss: 0.3372 - acc: 0.9375\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 500us/step - loss: 0.3331 - acc: 0.9375\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 243us/step - loss: 0.3290 - acc: 0.9375\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 125us/step - loss: 0.3250 - acc: 0.9375\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 130us/step - loss: 0.3210 - acc: 0.9375\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 131us/step - loss: 0.3170 - acc: 0.9375\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 496us/step - loss: 0.3131 - acc: 0.9375\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 117us/step - loss: 0.3092 - acc: 0.9375\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 239us/step - loss: 0.3053 - acc: 0.9375\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 440us/step - loss: 0.3014 - acc: 0.9375\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 359us/step - loss: 0.2976 - acc: 0.9375\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 106us/step - loss: 0.2938 - acc: 0.9375\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 332us/step - loss: 0.2901 - acc: 0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f9a840fcda0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_sentences, sentiments, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will train and test the model using the same corpus. \n",
    "\n",
    "# Execute the following script to evaluate the model performance on our corpus:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_sentences, sentiments, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Loading Pretrained Word Embeddings\n",
    "\n",
    "In the previous section we trained custom word embeddings. However, we can also use pretrained word embeddings.\n",
    "\n",
    "Several types of pretrained word embeddings exist, however we will be using the GloVe word embeddings from Stanford NLP since it is the most famous one and commonly used. The word embeddings can be downloaded from this link.\n",
    "\n",
    "The smallest file is named \"Glove.6B.zip\". The size of the file is 822 MB. The file contains 50, 100, 200, and 300 dimensional word vectors for 400k words. We will be using the 100 dimensional vector.\n",
    "\n",
    "The process is quite similar. First we have to import the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    # Positive Reviews\n",
    "\n",
    "    'This is an excellent movie',\n",
    "    'The move was fantastic I like it',\n",
    "    'You should watch it is brilliant',\n",
    "    'Exceptionally good',\n",
    "    'Wonderfully directed and executed I like it',\n",
    "    'Its a fantastic series',\n",
    "    'Never watched such a brillent movie',\n",
    "    'It is a Wonderful movie',\n",
    "\n",
    "    # Negtive Reviews\n",
    "\n",
    "    \"horrible acting\",\n",
    "    'waste of money',\n",
    "    'pathetic picture',\n",
    "    'It was very boring',\n",
    "    'I did not like the movie',\n",
    "    'The movie was horrible',\n",
    "    'I will not recommend',\n",
    "    'The acting is pathetic'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = array([1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last section, we used one_hot function to convert text to vectors. \n",
    "\n",
    "Another approach is to use Tokenizer function from keras.preprocessing.text library.\n",
    "\n",
    "You simply have to pass your corpus to the Tokenizer's fit_on_text method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the number of unique words in the text, you can simply count the length of word_index dictionary of the word_tokenizer object. \n",
    "\n",
    "Remember to add 1 with the vocabulary size. \n",
    "\n",
    "This is to store the dimensions for the words for which no pretrained word embeddings exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_length = len(word_tokenizer.word_index) + 1\n",
    "vocab_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to convert sentences to their numeric counterpart, call the texts_to_sequences function and pass it the whole corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14, 3, 15, 16, 1], [4, 17, 6, 9, 5, 7, 2], [18, 19, 20, 2, 3, 21], [22, 23], [24, 25, 26, 27, 5, 7, 2], [28, 8, 9, 29], [30, 31, 32, 8, 33, 1], [2, 3, 8, 34, 1], [10, 11], [35, 36, 37], [12, 38], [2, 6, 39, 40], [5, 41, 13, 7, 4, 1], [4, 1, 6, 10], [5, 42, 13, 43], [4, 11, 3, 12]]\n"
     ]
    }
   ],
   "source": [
    "embedded_sentences = word_tokenizer.texts_to_sequences(corpus)\n",
    "print(embedded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to find the number of words in the longest sentence \n",
    "and then to apply padding to the sentences having shorter lengths than the length of the longest sentence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  3 15 16  1  0  0]\n",
      " [ 4 17  6  9  5  7  2]\n",
      " [18 19 20  2  3 21  0]\n",
      " [22 23  0  0  0  0  0]\n",
      " [24 25 26 27  5  7  2]\n",
      " [28  8  9 29  0  0  0]\n",
      " [30 31 32  8 33  1  0]\n",
      " [ 2  3  8 34  1  0  0]\n",
      " [10 11  0  0  0  0  0]\n",
      " [35 36 37  0  0  0  0]\n",
      " [12 38  0  0  0  0  0]\n",
      " [ 2  6 39 40  0  0  0]\n",
      " [ 5 41 13  7  4  1  0]\n",
      " [ 4  1  6 10  0  0  0]\n",
      " [ 5 42 13 43  0  0  0]\n",
      " [ 4 11  3 12  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word_count = lambda sentence: len(word_tokenize(sentence))\n",
    "longest_sentence = max(corpus, key=word_count)\n",
    "length_long_sentence = len(word_tokenize(longest_sentence))\n",
    "\n",
    "padded_sentences = pad_sequences(embedded_sentences, length_long_sentence, padding='post')\n",
    "\n",
    "print(padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have converted our sentences into padded sequence of numbers. \n",
    "\n",
    "The next step is to load the GloVe word embeddings and \n",
    "\n",
    "then create our embedding matrix that contains the words in our corpus and their corresponding values from GloVe embeddings. Run the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open('/home/renuk/Documents/Deep_learning/notebooks/glove.6B/glove.6B.100d.txt', encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the script above, in addition to loading the GloVe embeddings, we also imported a few libraries.\n",
    "\n",
    "We will see the use of these libraries in the upcoming section. \n",
    "\n",
    "Here notice that we loaded glove.6B.100d.txt file. This file contains 100 dimensional word embeddings. \n",
    "\n",
    "We also created an empty dictionary that will store our word embeddings.\n",
    "\n",
    "If you open the file, you will see a word at the beginning of each line followed by set of 100 numbers. \n",
    "\n",
    "The numbers form the 100 dimensional vector for the word at the begining of each line.\n",
    "\n",
    "We will create a dictionary that will contain words as keys and the corresponding 100 dimensional vectors as values, in the form of an array. Execute the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary embeddings_dictionary now contains words and corresponding GloVe embeddings for all the words.\n",
    "\n",
    "We want the word embeddings for only those words that are present in our corpus. We will create a two dimensional numpy array of 44 (size of vocabulary) rows and 100 columns. The array will initially contain zeros. The array will be named as embedding_matrix\n",
    "\n",
    "Next, we will iterate through each word in our corpus by traversing the word_tokenizer.word_index dictionary that contains our words and their corresponding index.\n",
    "\n",
    "Each word will be passed as key to the embedding_dictionary to retrieve the corresponding 100 dimensional vector for the word. The 100 dimensional vector will then be stored at the corresponding index of the word in the embedding_matrix. Look at the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = zeros((vocab_length, 100))\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our embedding_matrix now contains pretrained word embeddings for the words in our corpus.\n",
    "\n",
    "Now we are ready to create our sequential model. Look at the following script:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script remains the same, except for the embedding layer. Here in the embedding layer, the first parameter is the size of the vacabulary. The second parameter is the vector dimension of the output vector. Since we are using pretrained word embeddings that contain 100 dimensional vector, we set the vector dimension to 100.\n",
    "\n",
    "Another very important attribute of the Embedding() layer that we did not use in the last section is weights. You can pass your pretrained embedding matrix as default weights to the weights parameter. And since we are not training the embedding layer, the trainable attribute has been set to False.\n",
    "\n",
    "Let's compile our model and see the summary of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 7, 100)            4400      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 701       \n",
      "=================================================================\n",
      "Total params: 5,101\n",
      "Trainable params: 701\n",
      "Non-trainable params: 4,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8417 - acc: 0.3750\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 103us/step - loss: 0.8181 - acc: 0.3750\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 80us/step - loss: 0.7923 - acc: 0.3750\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 83us/step - loss: 0.7667 - acc: 0.5000\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 74us/step - loss: 0.7419 - acc: 0.5000\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 78us/step - loss: 0.7182 - acc: 0.5625\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 151us/step - loss: 0.6954 - acc: 0.5625\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 121us/step - loss: 0.6737 - acc: 0.5625\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 92us/step - loss: 0.6527 - acc: 0.5625\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 197us/step - loss: 0.6325 - acc: 0.5625\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 501us/step - loss: 0.6129 - acc: 0.5625\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 149us/step - loss: 0.5939 - acc: 0.6875\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 138us/step - loss: 0.5754 - acc: 0.7500\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 191us/step - loss: 0.5575 - acc: 0.7500\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 631us/step - loss: 0.5402 - acc: 0.7500\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 195us/step - loss: 0.5234 - acc: 0.7500\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 365us/step - loss: 0.5072 - acc: 0.7500\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 185us/step - loss: 0.4915 - acc: 0.7500\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 104us/step - loss: 0.4765 - acc: 0.8750\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 194us/step - loss: 0.4621 - acc: 0.8750\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 132us/step - loss: 0.4482 - acc: 0.8750\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 171us/step - loss: 0.4349 - acc: 0.8750\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 102us/step - loss: 0.4221 - acc: 0.8750\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 343us/step - loss: 0.4098 - acc: 0.9375\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 152us/step - loss: 0.3980 - acc: 0.9375\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 152us/step - loss: 0.3867 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 115us/step - loss: 0.3758 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 188us/step - loss: 0.3652 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 177us/step - loss: 0.3551 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 198us/step - loss: 0.3453 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 243us/step - loss: 0.3359 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 184us/step - loss: 0.3268 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 203us/step - loss: 0.3180 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 209us/step - loss: 0.3095 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 308us/step - loss: 0.3014 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 152us/step - loss: 0.2935 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 148us/step - loss: 0.2859 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 278us/step - loss: 0.2787 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 326us/step - loss: 0.2717 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 339us/step - loss: 0.2649 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 262us/step - loss: 0.2584 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 139us/step - loss: 0.2521 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 356us/step - loss: 0.2460 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 120us/step - loss: 0.2402 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 141us/step - loss: 0.2345 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 455us/step - loss: 0.2291 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 128us/step - loss: 0.2238 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 209us/step - loss: 0.2187 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 260us/step - loss: 0.2138 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 157us/step - loss: 0.2090 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 321us/step - loss: 0.2044 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 208us/step - loss: 0.2000 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 230us/step - loss: 0.1957 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 507us/step - loss: 0.1915 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 130us/step - loss: 0.1875 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 321us/step - loss: 0.1836 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 190us/step - loss: 0.1798 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 148us/step - loss: 0.1762 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 307us/step - loss: 0.1726 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 182us/step - loss: 0.1692 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 108us/step - loss: 0.1659 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 345us/step - loss: 0.1626 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 144us/step - loss: 0.1595 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 123us/step - loss: 0.1565 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 160us/step - loss: 0.1536 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 176us/step - loss: 0.1507 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 144us/step - loss: 0.1479 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 204us/step - loss: 0.1452 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 311us/step - loss: 0.1426 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 107us/step - loss: 0.1401 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 120us/step - loss: 0.1376 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 126us/step - loss: 0.1352 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 130us/step - loss: 0.1329 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 102us/step - loss: 0.1306 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 95us/step - loss: 0.1284 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 114us/step - loss: 0.1262 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 640us/step - loss: 0.1241 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 111us/step - loss: 0.1221 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 292us/step - loss: 0.1201 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 128us/step - loss: 0.1182 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 112us/step - loss: 0.1163 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 307us/step - loss: 0.1145 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 100us/step - loss: 0.1127 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 135us/step - loss: 0.1109 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 364us/step - loss: 0.1092 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 141us/step - loss: 0.1076 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 172us/step - loss: 0.1060 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 132us/step - loss: 0.1044 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 86us/step - loss: 0.1029 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 138us/step - loss: 0.1014 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 130us/step - loss: 0.0999 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 162us/step - loss: 0.0985 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 95us/step - loss: 0.0971 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 106us/step - loss: 0.0957 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 218us/step - loss: 0.0944 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 128us/step - loss: 0.0931 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 130us/step - loss: 0.0918 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 493us/step - loss: 0.0905 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 162us/step - loss: 0.0893 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 104us/step - loss: 0.0881 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc39869fe10>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_sentences, sentiments, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
